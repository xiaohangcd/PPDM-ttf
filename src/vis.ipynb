{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tensorboardX\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import _init_paths\n",
    "import torch\n",
    "import tensorwatch as tw\n",
    "from models.model import create_model, load_model, save_model\n",
    "from models.data_parallel import DataParallel\n",
    "from logger import Logger\n",
    "from datasets.dataset_factory import get_dataset\n",
    "from trains.train_factory import train_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "class opts(object):\n",
    "    def __init__(self):\n",
    "        self.parser = argparse.ArgumentParser()\n",
    "        # basic experiment setting\n",
    "        self.parser.add_argument('--task', default='hoidet',\n",
    "                                 help='ctdet | ddd | multi_pose | exdet')\n",
    "        self.parser.add_argument('--dataset', default='hico',\n",
    "                                 help='hico | vcoco | hoia')\n",
    "        self.parser.add_argument('--exp_id', default='default')\n",
    "        self.parser.add_argument('--test', action='store_true')\n",
    "        self.parser.add_argument('--debug', type=int, default=0,\n",
    "                                 help='level of visualization.'\n",
    "                                      '1: only show the final detection results'\n",
    "                                      '2: show the network output features'\n",
    "                                      '3: use matplot to display'  # useful when lunching training with ipython notebook\n",
    "                                      '4: save all visualizations to disk')\n",
    "        self.parser.add_argument('--demo', default='',\n",
    "                                 help='path to image/ image folders/ video. '\n",
    "                                      'or \"webcam\"')\n",
    "        self.parser.add_argument('--load_model', default='',\n",
    "                                 help='path to pretrained model')\n",
    "        self.parser.add_argument('--resume', action='store_true',\n",
    "                                 help='resume an experiment. '\n",
    "                                      'Reloaded the optimizer parameter and '\n",
    "                                      'set load_model to model_last.pth '\n",
    "                                      'in the exp dir if load_model is empty.')\n",
    "\n",
    "        # system\n",
    "        self.parser.add_argument('--gpus', default='0',\n",
    "                                 help='-1 for CPU, use comma for multiple gpus')\n",
    "        self.parser.add_argument('--num_workers', type=int, default=4,\n",
    "                                 help='dataloader threads. 0 for single-thread.')\n",
    "        self.parser.add_argument('--not_cuda_benchmark', action='store_true',\n",
    "                                 help='disable when the input size is not fixed.')\n",
    "        self.parser.add_argument('--seed', type=int, default=317,\n",
    "                                 help='random seed')  # from CornerNet\n",
    "\n",
    "        # log\n",
    "        self.parser.add_argument('--print_iter', type=int, default=0,\n",
    "                                 help='disable progress bar and print to screen.')\n",
    "        self.parser.add_argument('--hide_data_time', action='store_true',\n",
    "                                 help='not display time during training.')\n",
    "        self.parser.add_argument('--save_all', action='store_true',\n",
    "                                 help='save model to disk every 5 epochs.')\n",
    "        self.parser.add_argument('--metric', default='loss',\n",
    "                                 help='main metric to save best model')\n",
    "        self.parser.add_argument('--vis_thresh', type=float, default=0.3,\n",
    "                                 help='visualization threshold.')\n",
    "        self.parser.add_argument('--debugger_theme', default='white',\n",
    "                                 choices=['white', 'black'])\n",
    "\n",
    "        # model\n",
    "        self.parser.add_argument('--arch', default='dla_34',\n",
    "                                 help='model architecture. Currently tested'\n",
    "                                      'res_18 | resdcn_18 | dla_34 | hourglass')\n",
    "        self.parser.add_argument('--head_conv', type=int, default=-1,\n",
    "                                 help='conv layer channels for output head'\n",
    "                                      '0 for no conv layer'\n",
    "                                      '-1 for default setting: '\n",
    "                                      '64 for resnets and 256 for dla.')\n",
    "        self.parser.add_argument('--down_ratio', type=int, default=4,\n",
    "                                 help='output stride. Currently only supports 4.')\n",
    "\n",
    "        # input\n",
    "        self.parser.add_argument('--input_res', type=int, default=-1,\n",
    "                                 help='input height and width. -1 for default from '\n",
    "                                      'dataset. Will be overriden by input_h | input_w')\n",
    "        self.parser.add_argument('--input_h', type=int, default=-1,\n",
    "                                 help='input height. -1 for default from dataset.')\n",
    "        self.parser.add_argument('--input_w', type=int, default=-1,\n",
    "                                 help='input width. -1 for default from dataset.')\n",
    "\n",
    "        # train\n",
    "        self.parser.add_argument('--lr', type=float, default=1.25e-4,\n",
    "                                 help='learning rate for batch size 32.')\n",
    "        self.parser.add_argument('--lr_step', type=str, default='90,120',\n",
    "                                 help='drop learning rate by 10.')\n",
    "        self.parser.add_argument('--num_epochs', type=int, default=140,\n",
    "                                 help='total training epochs.')\n",
    "        self.parser.add_argument('--batch_size', type=int, default=32,\n",
    "                                 help='batch size')\n",
    "        self.parser.add_argument('--master_batch_size', type=int, default=-1,\n",
    "                                 help='batch size on the master gpu.')\n",
    "        self.parser.add_argument('--num_iters', type=int, default=-1,\n",
    "                                 help='default: #samples / batch_size.')\n",
    "        self.parser.add_argument('--val_intervals', type=int, default=100000,\n",
    "                                 help='number of epochs to run validation.')\n",
    "        self.parser.add_argument('--trainval', action='store_true',\n",
    "                                 help='include validation in training and '\n",
    "                                      'test on test set')\n",
    "\n",
    "        # test\n",
    "        self.parser.add_argument('--flip_test', action='store_true',\n",
    "                                 help='flip data augmentation.')\n",
    "        self.parser.add_argument('--test_scales', type=str, default='1',\n",
    "                                 help='multi scale test augmentation.')\n",
    "        self.parser.add_argument('--nms', action='store_true',\n",
    "                                 help='run nms in testing.')\n",
    "        self.parser.add_argument('--K', type=int, default=100,\n",
    "                                 help='max number of output objects.')\n",
    "        self.parser.add_argument('--not_prefetch_test', action='store_true',\n",
    "                                 help='not use parallal data pre-processing.')\n",
    "        self.parser.add_argument('--fix_res', action='store_true',\n",
    "                                 help='fix testing resolution or keep '\n",
    "                                      'the original resolution')\n",
    "        self.parser.add_argument('--keep_res', action='store_true',\n",
    "                                 help='keep the original resolution'\n",
    "                                      ' during validation.')\n",
    "        self.parser.add_argument('--save_predictions', action='store_true',\n",
    "                                 help='saving predictions when testing')\n",
    "        self.parser.add_argument('--test_with_eval', action='store_true',\n",
    "                                 help='do evaluation when testing')\n",
    "        self.parser.add_argument('--test_video', action='store_true',\n",
    "                                 help='inference with a video')\n",
    "        self.parser.add_argument('--test_dir', type=str,default='',\n",
    "                                 help='the video path')\n",
    "        self.parser.add_argument('--save_video', type=str,default='',\n",
    "                                 help='the video save path')\n",
    "\n",
    "        # dataset\n",
    "        self.parser.add_argument('--not_rand_crop', action='store_true',\n",
    "                                 help='not use the random crop data augmentation'\n",
    "                                      'from CornerNet.')\n",
    "        self.parser.add_argument('--shift', type=float, default=0.1,\n",
    "                                 help='when not using random crop'\n",
    "                                      'apply shift augmentation.')\n",
    "        self.parser.add_argument('--scale', type=float, default=0.4,\n",
    "                                 help='when not using random crop'\n",
    "                                      'apply scale augmentation.')\n",
    "        self.parser.add_argument('--rotate', type=float, default=0,\n",
    "                                 help='when not using random crop'\n",
    "                                      'apply rotation augmentation.')\n",
    "        self.parser.add_argument('--flip', type=float, default=0.5,\n",
    "                                 help='probability of applying flip augmentation.')\n",
    "        self.parser.add_argument('--no_color_aug', action='store_true',\n",
    "                                 help='not use the color augmenation '\n",
    "                                      'from CornerNet')\n",
    "\n",
    "\n",
    "        # loss\n",
    "        self.parser.add_argument('--mse_loss', action='store_true',\n",
    "                                 help='use mse loss or focal loss to train '\n",
    "                                      'keypoint heatmaps.')\n",
    "        # ctdet\n",
    "        self.parser.add_argument('--reg_loss', default='l1',\n",
    "                                 help='regression loss: sl1 | l1 | l2')\n",
    "        self.parser.add_argument('--hm_weight', type=float, default=1,\n",
    "                                 help='loss weight for keypoint heatmaps.')\n",
    "        self.parser.add_argument('--off_weight', type=float, default=1,\n",
    "                                 help='loss weight for keypoint local offsets.')\n",
    "        self.parser.add_argument('--wh_weight', type=float, default=0.1,\n",
    "                                 help='loss weight for bounding box size.')\n",
    "\n",
    "        # task\n",
    "        # ctdet\n",
    "        self.parser.add_argument('--norm_wh', action='store_true',\n",
    "                                 help='L1(\\hat(y) / y, 1) or L1(\\hat(y), y)')\n",
    "        self.parser.add_argument('--dense_wh', action='store_true',\n",
    "                                 help='apply weighted regression near center or '\n",
    "                                      'just apply regression on center point.')\n",
    "        self.parser.add_argument('--cat_spec_wh', action='store_true',\n",
    "                                 help='category specific bounding box size.')\n",
    "        self.parser.add_argument('--not_reg_offset', action='store_true',\n",
    "                                 help='not regress local offset.')\n",
    "\n",
    "        # ground truth validation\n",
    "        self.parser.add_argument('--image_dir', type=str, default='images/trainval',\n",
    "                                 help='training dataset path.')\n",
    "        self.parser.add_argument('--root_path', type=str, default='../Dataset',\n",
    "                                 help='training dataset path.')\n",
    "        self.parser.add_argument('--use_cos', type=int, default=0\n",
    "                                 , help='whether using cosine lr step policy')\n",
    "        self.parser.add_argument('--use_verb_sub', type=int, default=0\n",
    "                                 , help='whether using verb categories for subject')\n",
    "\n",
    "    def parse(self, args=''):\n",
    "        opt = self.parser.parse_known_args()[0]\n",
    "        print(opt.task)\n",
    "        opt.gpus_str = opt.gpus\n",
    "        opt.gpus = [int(gpu) for gpu in opt.gpus.split(',')]\n",
    "        opt.gpus = [i for i in range(len(opt.gpus))] if opt.gpus[0] >= 0 else [-1]\n",
    "        opt.lr_step = [int(i) for i in opt.lr_step.split(',')]\n",
    "        opt.test_scales = [float(i) for i in opt.test_scales.split(',')]\n",
    "\n",
    "        opt.fix_res = not opt.keep_res\n",
    "        print('Fix size testing.' if opt.fix_res else 'Keep resolution testing.')\n",
    "        opt.reg_offset = not opt.not_reg_offset\n",
    "\n",
    "        if opt.head_conv == -1:  # init default head_conv\n",
    "            opt.head_conv = 256 if 'dla' in opt.arch else 64\n",
    "        opt.pad = 127 if 'hourglass' in opt.arch else 31\n",
    "        opt.num_stacks = 2 if opt.arch == 'hourglass' else 1\n",
    "\n",
    "        if opt.trainval:\n",
    "            opt.val_intervals = 100000000\n",
    "\n",
    "        if opt.debug > 0:\n",
    "            opt.num_workers = 0\n",
    "            opt.batch_size = 1\n",
    "            opt.gpus = [opt.gpus[0]]\n",
    "            opt.master_batch_size = -1\n",
    "\n",
    "        if opt.master_batch_size == -1:\n",
    "            opt.master_batch_size = opt.batch_size // len(opt.gpus)\n",
    "        rest_batch_size = (opt.batch_size - opt.master_batch_size)\n",
    "        opt.chunk_sizes = [opt.master_batch_size]\n",
    "        for i in range(len(opt.gpus) - 1):\n",
    "            slave_chunk_size = rest_batch_size // (len(opt.gpus) - 1)\n",
    "            if i < rest_batch_size % (len(opt.gpus) - 1):\n",
    "                slave_chunk_size += 1\n",
    "            opt.chunk_sizes.append(slave_chunk_size)\n",
    "        print('training chunk_sizes:', opt.chunk_sizes)\n",
    "\n",
    "\n",
    "        if opt.resume and opt.load_model == '':\n",
    "            model_path = opt.save_dir[:-4] if opt.save_dir.endswith('TEST') \\\n",
    "                else opt.save_dir\n",
    "            opt.load_model = os.path.join(model_path, 'model_last.pth')\n",
    "        return opt\n",
    "\n",
    "    def update_dataset_info_and_set_heads(self, opt, dataset):\n",
    "        input_h, input_w = dataset.default_resolution\n",
    "        opt.mean, opt.std = dataset.mean, dataset.std\n",
    "        opt.num_classes = dataset.num_classes\n",
    "        opt.num_classes_verb = dataset.num_classes_verb\n",
    "        # input_h(w): opt.input_h overrides opt.input_res overrides dataset default\n",
    "        input_h = opt.input_res if opt.input_res > 0 else input_h\n",
    "        input_w = opt.input_res if opt.input_res > 0 else input_w\n",
    "        opt.input_h = opt.input_h if opt.input_h > 0 else input_h\n",
    "        opt.input_w = opt.input_w if opt.input_w > 0 else input_w\n",
    "        opt.output_h = opt.input_h // opt.down_ratio\n",
    "        opt.output_w = opt.input_w // opt.down_ratio\n",
    "        opt.input_res = max(opt.input_h, opt.input_w)\n",
    "        opt.output_res = max(opt.output_h, opt.output_w)\n",
    "\n",
    "\n",
    "        if opt.task == 'hoidet':\n",
    "            assert opt.dataset in ['hico', 'vcoco', 'hoia']\n",
    "            opt.heads = {'hm': opt.num_classes,\n",
    "                         'wh': 2 if not opt.cat_spec_wh else 2 * opt.num_classes,\n",
    "                         'hm_rel': opt.num_classes_verb,\n",
    "                         'sub_offset': 2 * opt.num_classes_verb,\n",
    "                         'obj_offset': 2 * opt.num_classes_verb}\n",
    "            if opt.reg_offset:\n",
    "                opt.heads.update({'reg': 2})\n",
    "        else:\n",
    "            assert 0, 'task not defined!'\n",
    "        print('heads', opt.heads)\n",
    "        return opt\n",
    "\n",
    "    def init(self, args=''):\n",
    "        default_dataset_info = {\n",
    "            'hoidet': {'default_resolution': [512, 512], 'num_classes': 80,\n",
    "                  'mean': [0.408, 0.447, 0.470], 'std': [0.289, 0.274, 0.278],\n",
    "                  'dataset': 'hico', 'num_classes_verb': 117}\n",
    "        }\n",
    "\n",
    "        class Struct:\n",
    "            def __init__(self, entries):\n",
    "                for k, v in entries.items():\n",
    "                    self.__setattr__(k, v)\n",
    "\n",
    "        opt = self.parse(args)\n",
    "        dataset = Struct(default_dataset_info[opt.task])\n",
    "        opt.dataset = dataset.dataset\n",
    "        opt = self.update_dataset_info_and_set_heads(opt, dataset)\n",
    "        return opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database is locked')).History will not be written to the database.hoidet\n",
      "\n",
      "Fix size testing.\n",
      "training chunk_sizes: [32]\n"
     ]
    }
   ],
   "source": [
    "opt = opts().parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heads {'hm': 80, 'wh': 2, 'hm_rel': 117, 'sub_offset': 234, 'obj_offset': 234, 'reg': 2}\n",
      "Namespace(K=100, arch='dla_34', batch_size=32, cat_spec_wh=False, chunk_sizes=[32], dataset='hico', debug=0, debugger_theme='white', demo='', dense_wh=False, down_ratio=4, exp_id='default', fix_res=True, flip=0.5, flip_test=False, gpus=[0], gpus_str='0', head_conv=256, heads={'hm': 80, 'wh': 2, 'hm_rel': 117, 'sub_offset': 234, 'obj_offset': 234, 'reg': 2}, hide_data_time=False, hm_weight=1, image_dir='images/trainval', input_h=512, input_res=512, input_w=512, keep_res=False, load_model='', lr=0.000125, lr_step=[90, 120], master_batch_size=32, mean=array([[[0.40789655, 0.44719303, 0.47026116]]], dtype=float32), metric='loss', mse_loss=False, nms=False, no_color_aug=False, norm_wh=False, not_cuda_benchmark=False, not_prefetch_test=False, not_rand_crop=False, not_reg_offset=False, num_classes=80, num_classes_verb=117, num_epochs=140, num_iters=-1, num_stacks=1, num_workers=4, off_weight=1, output_h=128, output_res=128, output_w=128, pad=31, print_iter=0, reg_loss='l1', reg_offset=True, resume=False, root_path='../Dataset', rotate=0, save_all=False, save_predictions=False, save_video='', scale=0.4, seed=317, shift=0.1, std=array([[[0.2886383 , 0.27408165, 0.27809834]]], dtype=float32), task='hoidet', test=False, test_dir='', test_scales=[1.0], test_video=False, test_with_eval=False, trainval=False, use_cos=0, use_verb_sub=0, val_intervals=100000, vis_thresh=0.3, wh_weight=0.1)\n"
     ]
    }
   ],
   "source": [
    "Dataset = get_dataset(opt.dataset)\n",
    "opt = opts().update_dataset_info_and_set_heads(opt, Dataset)\n",
    "print(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(opt.arch, opt.heads, opt.head_conv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLASeg(\n",
      "  (base): DLA(\n",
      "    (base_layer): Sequential(\n",
      "      (0): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (level0): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (level1): Sequential(\n",
      "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (level2): Tree(\n",
      "      (tree1): BasicBlock(\n",
      "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (tree2): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (root): Root(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (project): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (level3): Tree(\n",
      "      (tree1): Tree(\n",
      "        (tree1): BasicBlock(\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (tree2): BasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (root): Root(\n",
      "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "        (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (project): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (tree2): Tree(\n",
      "        (tree1): BasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (tree2): BasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (root): Root(\n",
      "          (conv): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (project): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (level4): Tree(\n",
      "      (tree1): Tree(\n",
      "        (tree1): BasicBlock(\n",
      "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (tree2): BasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (root): Root(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "        (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (project): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (tree2): Tree(\n",
      "        (tree1): BasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (tree2): BasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (root): Root(\n",
      "          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (project): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (level5): Tree(\n",
      "      (tree1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (tree2): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (root): Root(\n",
      "        (conv): Conv2d(1280, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (project): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (fc): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (dla_up): DLAUp(\n",
      "    (ida_0): IDAUp(\n",
      "      (proj_1): DeformConv(\n",
      "        (actf): Sequential(\n",
      "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (conv): DCN(\n",
      "          (conv_offset_mask): Conv2d(512, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (up_1): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
      "      (node_1): DeformConv(\n",
      "        (actf): Sequential(\n",
      "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (conv): DCN(\n",
      "          (conv_offset_mask): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ida_1): IDAUp(\n",
      "      (proj_1): DeformConv(\n",
      "        (actf): Sequential(\n",
      "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (conv): DCN(\n",
      "          (conv_offset_mask): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (up_1): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "      (node_1): DeformConv(\n",
      "        (actf): Sequential(\n",
      "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (conv): DCN(\n",
      "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (proj_2): DeformConv(\n",
      "        (actf): Sequential(\n",
      "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (conv): DCN(\n",
      "          (conv_offset_mask): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (up_2): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "      (node_2): DeformConv(\n",
      "        (actf): Sequential(\n",
      "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (conv): DCN(\n",
      "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ida_2): IDAUp(\n",
      "      (proj_1): DeformConv(\n",
      "        (actf): Sequential(\n",
      "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (conv): DCN(\n",
      "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (up_1): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "      (node_1): DeformConv(\n",
      "        (actf): Sequential(\n",
      "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (conv): DCN(\n",
      "          (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (proj_2): DeformConv(\n",
      "        (actf): Sequential(\n",
      "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (conv): DCN(\n",
      "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (up_2): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "      (node_2): DeformConv(\n",
      "        (actf): Sequential(\n",
      "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (conv): DCN(\n",
      "          (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (proj_3): DeformConv(\n",
      "        (actf): Sequential(\n",
      "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (conv): DCN(\n",
      "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (up_3): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "      (node_3): DeformConv(\n",
      "        (actf): Sequential(\n",
      "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (conv): DCN(\n",
      "          (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ida_up): IDAUp(\n",
      "    (proj_1): DeformConv(\n",
      "      (actf): Sequential(\n",
      "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU(inplace)\n",
      "      )\n",
      "      (conv): DCN(\n",
      "        (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (up_1): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "    (node_1): DeformConv(\n",
      "      (actf): Sequential(\n",
      "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU(inplace)\n",
      "      )\n",
      "      (conv): DCN(\n",
      "        (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (proj_2): DeformConv(\n",
      "      (actf): Sequential(\n",
      "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU(inplace)\n",
      "      )\n",
      "      (conv): DCN(\n",
      "        (conv_offset_mask): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (up_2): ConvTranspose2d(64, 64, kernel_size=(8, 8), stride=(4, 4), padding=(2, 2), groups=64, bias=False)\n",
      "    (node_2): DeformConv(\n",
      "      (actf): Sequential(\n",
      "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU(inplace)\n",
      "      )\n",
      "      (conv): DCN(\n",
      "        (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (hm): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (wh): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (hm_rel): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(256, 117, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (sub_offset): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(256, 234, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (obj_offset): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(256, 234, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (reg): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.rand(2,3,512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DLASeg(\n",
       "  (base): DLA(\n",
       "    (base_layer): Sequential(\n",
       "      (0): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace)\n",
       "    )\n",
       "    (level0): Sequential(\n",
       "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace)\n",
       "    )\n",
       "    (level1): Sequential(\n",
       "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace)\n",
       "    )\n",
       "    (level2): Tree(\n",
       "      (tree1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (tree2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (root): Root(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (level3): Tree(\n",
       "      (tree1): Tree(\n",
       "        (tree1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (tree2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (root): Root(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (project): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (tree2): Tree(\n",
       "        (tree1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (tree2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (root): Root(\n",
       "          (conv): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (level4): Tree(\n",
       "      (tree1): Tree(\n",
       "        (tree1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (tree2): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (root): Root(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (project): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (tree2): Tree(\n",
       "        (tree1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (tree2): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (root): Root(\n",
       "          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (level5): Tree(\n",
       "      (tree1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (tree2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (root): Root(\n",
       "        (conv): Conv2d(1280, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (fc): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (dla_up): DLAUp(\n",
       "    (ida_0): IDAUp(\n",
       "      (proj_1): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): DCN(\n",
       "          (conv_offset_mask): Conv2d(512, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (up_1): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "      (node_1): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): DCN(\n",
       "          (conv_offset_mask): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ida_1): IDAUp(\n",
       "      (proj_1): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): DCN(\n",
       "          (conv_offset_mask): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (up_1): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "      (node_1): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): DCN(\n",
       "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (proj_2): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): DCN(\n",
       "          (conv_offset_mask): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (up_2): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "      (node_2): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): DCN(\n",
       "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ida_2): IDAUp(\n",
       "      (proj_1): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): DCN(\n",
       "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (up_1): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "      (node_1): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): DCN(\n",
       "          (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (proj_2): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): DCN(\n",
       "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (up_2): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "      (node_2): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): DCN(\n",
       "          (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (proj_3): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): DCN(\n",
       "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (up_3): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "      (node_3): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): DCN(\n",
       "          (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ida_up): IDAUp(\n",
       "    (proj_1): DeformConv(\n",
       "      (actf): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace)\n",
       "      )\n",
       "      (conv): DCN(\n",
       "        (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (up_1): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "    (node_1): DeformConv(\n",
       "      (actf): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace)\n",
       "      )\n",
       "      (conv): DCN(\n",
       "        (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (proj_2): DeformConv(\n",
       "      (actf): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace)\n",
       "      )\n",
       "      (conv): DCN(\n",
       "        (conv_offset_mask): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (up_2): ConvTranspose2d(64, 64, kernel_size=(8, 8), stride=(4, 4), padding=(2, 2), groups=64, bias=False)\n",
       "    (node_2): DeformConv(\n",
       "      (actf): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace)\n",
       "      )\n",
       "      (conv): DCN(\n",
       "        (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (hm): Sequential(\n",
       "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (wh): Sequential(\n",
       "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (hm_rel): Sequential(\n",
       "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(256, 117, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (sub_offset): Sequential(\n",
       "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(256, 234, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (obj_offset): Sequential(\n",
       "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(256, 234, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (reg): Sequential(\n",
       "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(inp.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hm torch.Size([2, 80, 128, 128])\n",
      "wh torch.Size([2, 2, 128, 128])\n",
      "hm_rel torch.Size([2, 117, 128, 128])\n",
      "sub_offset torch.Size([2, 234, 128, 128])\n",
      "obj_offset torch.Size([2, 234, 128, 128])\n",
      "reg torch.Size([2, 2, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "for key in out[0]:\n",
    "    print(key,out[0][key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoi_annotation = json.load(open('../Dataset/hico_det/annotations/trainval_hico.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(hoi_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'HICO_train2015_00000010.jpg',\n",
       " 'img_id': 10,\n",
       " 'annotations': [{'bbox': [266, 69, 369, 273], 'category_id': 1},\n",
       "  {'bbox': [111, 69, 442, 410], 'category_id': 19},\n",
       "  {'bbox': [282, 65, 353, 288], 'category_id': 1},\n",
       "  {'bbox': [97, 68, 448, 416], 'category_id': 19}],\n",
       " 'hoi_annotation': [{'subject_id': 0,\n",
       "   'object_id': 1,\n",
       "   'category_id': 37,\n",
       "   'hoi_category_id': 132},\n",
       "  {'subject_id': 0, 'object_id': 1, 'category_id': 77, 'hoi_category_id': 140},\n",
       "  {'subject_id': 2,\n",
       "   'object_id': 3,\n",
       "   'category_id': 99,\n",
       "   'hoi_category_id': 142}]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hoi_annotation[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37633"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hoi_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.new_zeros((8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[6.4284e-01, 4.5300e-01, 1.6063e-01,  ..., 8.3155e-01,\n",
       "           6.7112e-01, 7.4838e-02],\n",
       "          [2.5540e-01, 5.5879e-01, 2.9102e-01,  ..., 1.9157e-02,\n",
       "           7.3649e-01, 9.4765e-01],\n",
       "          [9.7452e-01, 6.1641e-01, 2.4284e-01,  ..., 1.6031e-01,\n",
       "           9.7933e-01, 1.6624e-01],\n",
       "          ...,\n",
       "          [3.0959e-02, 8.5629e-01, 4.1204e-01,  ..., 1.4710e-01,\n",
       "           5.7472e-01, 9.9365e-01],\n",
       "          [6.3456e-01, 2.4013e-01, 8.8683e-01,  ..., 9.6062e-01,\n",
       "           2.2913e-01, 9.9980e-01],\n",
       "          [1.8317e-01, 8.2605e-01, 8.7873e-01,  ..., 9.0550e-01,\n",
       "           9.7295e-01, 8.4975e-01]],\n",
       "\n",
       "         [[1.5791e-01, 7.9024e-01, 1.6684e-01,  ..., 3.7241e-01,\n",
       "           6.7908e-01, 9.9644e-01],\n",
       "          [6.6486e-01, 2.0115e-02, 9.6444e-01,  ..., 1.8604e-01,\n",
       "           6.0808e-01, 9.3466e-01],\n",
       "          [3.7497e-01, 7.2220e-01, 8.1125e-01,  ..., 6.7297e-01,\n",
       "           5.8954e-01, 7.1415e-02],\n",
       "          ...,\n",
       "          [2.6642e-01, 3.2239e-01, 3.9868e-02,  ..., 4.4832e-01,\n",
       "           5.5324e-01, 9.8873e-01],\n",
       "          [2.8196e-01, 9.8374e-02, 4.4000e-01,  ..., 2.5574e-01,\n",
       "           2.3767e-01, 6.2364e-01],\n",
       "          [8.5156e-01, 1.3360e-01, 4.6940e-01,  ..., 5.0062e-02,\n",
       "           3.3854e-02, 6.3961e-01]],\n",
       "\n",
       "         [[8.4815e-01, 4.1732e-02, 6.8308e-01,  ..., 2.1128e-01,\n",
       "           3.6663e-01, 1.2396e-01],\n",
       "          [7.4596e-02, 2.4783e-02, 3.6142e-01,  ..., 8.7077e-01,\n",
       "           6.5555e-01, 4.9992e-01],\n",
       "          [1.6596e-01, 1.0583e-01, 2.9733e-01,  ..., 1.9274e-02,\n",
       "           2.6243e-01, 7.8596e-01],\n",
       "          ...,\n",
       "          [2.0280e-01, 7.1224e-01, 1.9318e-01,  ..., 3.7877e-01,\n",
       "           9.3302e-01, 5.9391e-01],\n",
       "          [5.9553e-01, 1.9753e-01, 9.7409e-01,  ..., 5.0560e-01,\n",
       "           3.8115e-01, 3.4428e-01],\n",
       "          [8.8715e-01, 9.9536e-01, 8.1507e-01,  ..., 7.8270e-01,\n",
       "           4.5301e-01, 1.2231e-01]]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "_valid_ids_verb = list(range(118))\n",
    "_valid_ids_verb.remove(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_ids_verb = {v: i for i, v in enumerate(_valid_ids_verb)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0,\n",
       " 2: 1,\n",
       " 3: 2,\n",
       " 4: 3,\n",
       " 5: 4,\n",
       " 6: 5,\n",
       " 7: 6,\n",
       " 8: 7,\n",
       " 9: 8,\n",
       " 10: 9,\n",
       " 11: 10,\n",
       " 12: 11,\n",
       " 13: 12,\n",
       " 14: 13,\n",
       " 15: 14,\n",
       " 16: 15,\n",
       " 17: 16,\n",
       " 18: 17,\n",
       " 19: 18,\n",
       " 20: 19,\n",
       " 21: 20,\n",
       " 22: 21,\n",
       " 23: 22,\n",
       " 24: 23,\n",
       " 25: 24,\n",
       " 26: 25,\n",
       " 27: 26,\n",
       " 28: 27,\n",
       " 29: 28,\n",
       " 30: 29,\n",
       " 31: 30,\n",
       " 32: 31,\n",
       " 33: 32,\n",
       " 34: 33,\n",
       " 35: 34,\n",
       " 36: 35,\n",
       " 37: 36,\n",
       " 38: 37,\n",
       " 39: 38,\n",
       " 40: 39,\n",
       " 41: 40,\n",
       " 42: 41,\n",
       " 43: 42,\n",
       " 44: 43,\n",
       " 45: 44,\n",
       " 46: 45,\n",
       " 47: 46,\n",
       " 48: 47,\n",
       " 49: 48,\n",
       " 50: 49,\n",
       " 51: 50,\n",
       " 52: 51,\n",
       " 53: 52,\n",
       " 54: 53,\n",
       " 55: 54,\n",
       " 56: 55,\n",
       " 57: 56,\n",
       " 58: 57,\n",
       " 59: 58,\n",
       " 60: 59,\n",
       " 61: 60,\n",
       " 62: 61,\n",
       " 63: 62,\n",
       " 64: 63,\n",
       " 65: 64,\n",
       " 66: 65,\n",
       " 67: 66,\n",
       " 68: 67,\n",
       " 69: 68,\n",
       " 70: 69,\n",
       " 71: 70,\n",
       " 72: 71,\n",
       " 73: 72,\n",
       " 74: 73,\n",
       " 75: 74,\n",
       " 76: 75,\n",
       " 77: 76,\n",
       " 78: 77,\n",
       " 79: 78,\n",
       " 80: 79,\n",
       " 81: 80,\n",
       " 82: 81,\n",
       " 83: 82,\n",
       " 84: 83,\n",
       " 85: 84,\n",
       " 86: 85,\n",
       " 87: 86,\n",
       " 88: 87,\n",
       " 89: 88,\n",
       " 90: 89,\n",
       " 91: 90,\n",
       " 92: 91,\n",
       " 93: 92,\n",
       " 94: 93,\n",
       " 95: 94,\n",
       " 96: 95,\n",
       " 97: 96,\n",
       " 98: 97,\n",
       " 99: 98,\n",
       " 100: 99,\n",
       " 101: 100,\n",
       " 102: 101,\n",
       " 103: 102,\n",
       " 104: 103,\n",
       " 105: 104,\n",
       " 106: 105,\n",
       " 107: 106,\n",
       " 108: 107,\n",
       " 109: 108,\n",
       " 110: 109,\n",
       " 111: 110,\n",
       " 112: 111,\n",
       " 113: 112,\n",
       " 114: 113,\n",
       " 115: 114,\n",
       " 116: 115,\n",
       " 117: 116}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_ids_verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_gaussian_mask(heatmap, center, sigma):\n",
    "  tmp_size = sigma * 3\n",
    "  mu_x = int(center[0] + 0.5)\n",
    "  mu_y = int(center[1] + 0.5)\n",
    "  w, h = heatmap.shape[0], heatmap.shape[1]\n",
    "  ul = [int(mu_x - tmp_size), int(mu_y - tmp_size)]\n",
    "  br = [int(mu_x + tmp_size + 1), int(mu_y + tmp_size + 1)]\n",
    "  if ul[0] >= h or ul[1] >= w or br[0] < 0 or br[1] < 0:\n",
    "    return heatmap\n",
    "  size = 2 * tmp_size + 1\n",
    "  x = np.arange(0, size, 1, np.float32)\n",
    "  y = x[:, np.newaxis]\n",
    "  x0 = y0 = size // 2\n",
    "  g = np.exp(- ((x - x0) ** 2 + (y - y0) ** 2) / (2 * sigma ** 2))\n",
    "  g_x = max(0, -ul[0]), min(br[0], h) - ul[0]\n",
    "  g_y = max(0, -ul[1]), min(br[1], w) - ul[1]\n",
    "  img_x = max(0, ul[0]), min(br[0], h)\n",
    "  img_y = max(0, ul[1]), min(br[1], w)\n",
    "  heatmap[img_y[0]:img_y[1], img_x[0]:img_x[1]] = np.maximum(\n",
    "    heatmap[img_y[0]:img_y[1], img_x[0]:img_x[1]],\n",
    "    g[g_y[0]:g_y[1], g_x[0]:g_x[1]])\n",
    "  \n",
    "  return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = np.zeros((8,8),dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = draw_gaussian_mask(heatmap,(4,4),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[x>0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = np.zeros((8, 2, 8, 8), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2, 8, 8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "off = offset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(off.shape[1]):\n",
    "    for j in range(off.shape[2]):\n",
    "        off[:,i,j] = i-0,j-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2.], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off[:,1,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_offset(offset_heatmap, point):\n",
    "  x,y = point\n",
    "  for i in range(offset_heatmap.shape[1]):\n",
    "      for j in range(offset_heatmap.shape[2]):\n",
    "          offset_heatmap[:,i,j] = i-x,j-y\n",
    "  return offset_heatmap  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.],\n",
       "        [ 3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.],\n",
       "        [ 4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.],\n",
       "        [ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.],\n",
       "        [ 6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.],\n",
       "        [ 7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.]],\n",
       "\n",
       "       [[-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.]]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_offset(off,[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.],\n",
       "        [ 3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.],\n",
       "        [ 4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.],\n",
       "        [ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.],\n",
       "        [ 6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.],\n",
       "        [ 7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.]],\n",
       "\n",
       "       [[-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.]]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gather_feat(feat, ind, mask=None):\n",
    "    dim  = feat.size(2)\n",
    "    ind  = ind.unsqueeze(2).expand(ind.size(0), ind.size(1), dim)\n",
    "    feat = feat.gather(1, ind)\n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(2).expand_as(feat)\n",
    "        feat = feat[mask]\n",
    "        feat = feat.view(-1, dim)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    " def _tranpose_and_gather_feat(feat, ind):\n",
    "    feat = feat.permute(0, 2, 3, 1).contiguous()\n",
    "    feat = feat.view(feat.size(0), -1, feat.size(3))\n",
    "    feat = _gather_feat(feat, ind)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = torch.rand(2,2,128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = torch.randint(128*128,(2,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2008., 13462.,  2232.,  3353.,   143., 14115.,  3965.,  1834.,  1802.,\n",
       "          5814.],\n",
       "        [ 8047.,  6783., 12222.,  1929., 11991., 15780., 11963.,  5402.,  3527.,\n",
       "         10543.]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind  = ind.unsqueeze(2).expand(ind.size(0), ind.size(1), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2008.,  2008.],\n",
       "         [13462., 13462.],\n",
       "         [ 2232.,  2232.],\n",
       "         [ 3353.,  3353.],\n",
       "         [  143.,   143.],\n",
       "         [14115., 14115.],\n",
       "         [ 3965.,  3965.],\n",
       "         [ 1834.,  1834.],\n",
       "         [ 1802.,  1802.],\n",
       "         [ 5814.,  5814.]],\n",
       "\n",
       "        [[ 8047.,  8047.],\n",
       "         [ 6783.,  6783.],\n",
       "         [12222., 12222.],\n",
       "         [ 1929.,  1929.],\n",
       "         [11991., 11991.],\n",
       "         [15780., 15780.],\n",
       "         [11963., 11963.],\n",
       "         [ 5402.,  5402.],\n",
       "         [ 3527.,  3527.],\n",
       "         [10543., 10543.]]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = feat.permute(0, 2, 3, 1).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = feat.view(feat.size(0), -1, feat.size(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16384, 234])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim  = feat.size(2)\n",
    "ind  = ind.unsqueeze(2).expand(ind.size(0), ind.size(1), dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = ind.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = _tranpose_and_gather_feat(feat, ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 2])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.rand(2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[mask>0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = mask.unsqueeze(2).expand_as(x).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 2])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "suboffset = torch.rand(2,10,2,128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 2, 128, 128])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suboffset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (128) must match the size of tensor b (2) at non-singleton dimension 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-f65f527deac5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msuboffset\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (128) must match the size of tensor b (2) at non-singleton dimension 4"
     ]
    }
   ],
   "source": [
    "suboffset*mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.rand(2,234,128,128)\n",
    "target = torch.rand(2,234,128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = F.l1_loss(pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3316)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.rand(2,234,4,4)\n",
    "id = torch.randint(117,(2,4)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 234, 4, 4])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= output.view(output.size(0),-1,2,output.size(2),output.size(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 117, 2, 4, 4])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[105,   1,  91,  65],\n",
       "        [111,  89,  37,   8]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = id.unsqueeze(2).unsqueeze(3).unsqueeze(4).expand(id.size(0), id.size(1), 2, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 2, 4, 4])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 117, 2, 4, 4])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2596, 0.8252, 0.1158, 0.2447],\n",
       "         [0.7099, 0.2261, 0.2139, 0.8317],\n",
       "         [0.9090, 0.4839, 0.4155, 0.3707],\n",
       "         [0.9032, 0.8130, 0.8953, 0.6375]],\n",
       "\n",
       "        [[0.3199, 0.1705, 0.3966, 0.7048],\n",
       "         [0.5049, 0.6957, 0.9793, 0.9772],\n",
       "         [0.9594, 0.4095, 0.5173, 0.2640],\n",
       "         [0.4259, 0.7042, 0.3473, 0.9461]]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1,111,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.gather(1,id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 2, 4, 4])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9467, 0.2668, 0.2382, 0.3521],\n",
       "         [0.2258, 0.0303, 0.7459, 0.9404],\n",
       "         [0.3269, 0.3035, 0.3804, 0.2106],\n",
       "         [0.9162, 0.1702, 0.7730, 0.5266]],\n",
       "\n",
       "        [[0.6122, 0.1753, 0.8452, 0.6629],\n",
       "         [0.2326, 0.7061, 0.5225, 0.4258],\n",
       "         [0.4373, 0.4352, 0.3213, 0.9018],\n",
       "         [0.6343, 0.4178, 0.2191, 0.2581]]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.rand(2,4,4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.4973, 0.0332, 0.2315, 0.8644],\n",
       "          [0.6310, 0.3141, 0.2344, 0.8679],\n",
       "          [0.3102, 0.7997, 0.8978, 0.1184],\n",
       "          [0.0268, 0.7056, 0.1279, 0.1426]],\n",
       "\n",
       "         [[0.2721, 0.1636, 0.9796, 0.6561],\n",
       "          [0.7841, 0.0904, 0.2888, 0.7617],\n",
       "          [0.2891, 0.6875, 0.3316, 0.2118],\n",
       "          [0.0512, 0.4419, 0.1532, 0.2235]],\n",
       "\n",
       "         [[0.0761, 0.1278, 0.8982, 0.0845],\n",
       "          [0.9963, 0.6068, 0.2757, 0.7953],\n",
       "          [0.0710, 0.7914, 0.9398, 0.9089],\n",
       "          [0.9368, 0.2734, 0.2056, 0.9034]],\n",
       "\n",
       "         [[0.5141, 0.6622, 0.2205, 0.7425],\n",
       "          [0.1222, 0.5994, 0.1914, 0.5262],\n",
       "          [0.0427, 0.5635, 0.6132, 0.8983],\n",
       "          [0.7985, 0.5426, 0.7088, 0.9586]]],\n",
       "\n",
       "\n",
       "        [[[0.7212, 0.6055, 0.0393, 0.4090],\n",
       "          [0.9266, 0.6836, 0.6747, 0.7840],\n",
       "          [0.1797, 0.5415, 0.3222, 0.4587],\n",
       "          [0.7273, 0.4992, 0.6190, 0.5999]],\n",
       "\n",
       "         [[0.2046, 0.4445, 0.6859, 0.2021],\n",
       "          [0.2625, 0.3422, 0.1228, 0.8654],\n",
       "          [0.3987, 0.9896, 0.2887, 0.6383],\n",
       "          [0.1221, 0.0463, 0.5793, 0.1755]],\n",
       "\n",
       "         [[0.5886, 0.0125, 0.6473, 0.3397],\n",
       "          [0.2095, 0.8832, 0.7624, 0.9042],\n",
       "          [0.2410, 0.2980, 0.4468, 0.9308],\n",
       "          [0.2334, 0.6222, 0.2837, 0.0327]],\n",
       "\n",
       "         [[0.5371, 0.6139, 0.5756, 0.8891],\n",
       "          [0.7736, 0.4084, 0.1583, 0.6386],\n",
       "          [0.7376, 0.8739, 0.2951, 0.9593],\n",
       "          [0.1840, 0.6229, 0.5199, 0.7129]]]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = mask.unsqueeze(2).expand_as(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[0.4708, 0.0088, 0.0551, 0.3043],\n",
       "           [0.1425, 0.0095, 0.1748, 0.8162],\n",
       "           [0.1014, 0.2427, 0.3415, 0.0249],\n",
       "           [0.0246, 0.1201, 0.0988, 0.0751]],\n",
       "\n",
       "          [[0.3044, 0.0058, 0.1956, 0.5730],\n",
       "           [0.1468, 0.2218, 0.1225, 0.3695],\n",
       "           [0.1357, 0.3481, 0.2885, 0.1068],\n",
       "           [0.0170, 0.2948, 0.0280, 0.0368]]],\n",
       "\n",
       "\n",
       "         [[[0.0043, 0.0890, 0.9479, 0.3155],\n",
       "           [0.2385, 0.0095, 0.0611, 0.5544],\n",
       "           [0.2785, 0.2126, 0.2259, 0.1132],\n",
       "           [0.0246, 0.3990, 0.0978, 0.1498]],\n",
       "\n",
       "          [[0.1547, 0.1405, 0.8287, 0.4969],\n",
       "           [0.7757, 0.0391, 0.2874, 0.4244],\n",
       "           [0.2253, 0.0408, 0.0226, 0.0851],\n",
       "           [0.0036, 0.0173, 0.0999, 0.0546]]],\n",
       "\n",
       "\n",
       "         [[[0.0740, 0.0478, 0.1905, 0.0162],\n",
       "           [0.3143, 0.5649, 0.2359, 0.6844],\n",
       "           [0.0619, 0.3187, 0.0799, 0.4072],\n",
       "           [0.3117, 0.2551, 0.1199, 0.8399]],\n",
       "\n",
       "          [[0.0033, 0.0528, 0.6521, 0.0039],\n",
       "           [0.3385, 0.2255, 0.0679, 0.3948],\n",
       "           [0.0488, 0.7197, 0.3669, 0.6958],\n",
       "           [0.6651, 0.1079, 0.1619, 0.3424]]],\n",
       "\n",
       "\n",
       "         [[[0.4926, 0.4101, 0.2140, 0.3083],\n",
       "           [0.0546, 0.1219, 0.1250, 0.4541],\n",
       "           [0.0084, 0.5151, 0.4781, 0.8043],\n",
       "           [0.3073, 0.4975, 0.3201, 0.7233]],\n",
       "\n",
       "          [[0.4109, 0.4899, 0.1041, 0.1687],\n",
       "           [0.0065, 0.1879, 0.1692, 0.2033],\n",
       "           [0.0059, 0.1805, 0.2641, 0.4788],\n",
       "           [0.1763, 0.0613, 0.4672, 0.1596]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[0.1872, 0.4996, 0.0046, 0.1001],\n",
       "           [0.6578, 0.1545, 0.1443, 0.6521],\n",
       "           [0.1633, 0.2620, 0.1339, 0.1700],\n",
       "           [0.6569, 0.4059, 0.5542, 0.3824]],\n",
       "\n",
       "          [[0.2307, 0.1032, 0.0156, 0.2883],\n",
       "           [0.4679, 0.4756, 0.6607, 0.7661],\n",
       "           [0.1724, 0.2218, 0.1667, 0.1211],\n",
       "           [0.3098, 0.3516, 0.2150, 0.5675]]],\n",
       "\n",
       "\n",
       "         [[[0.1597, 0.2532, 0.4949, 0.0128],\n",
       "           [0.0278, 0.3257, 0.0606, 0.5050],\n",
       "           [0.0869, 0.6994, 0.1380, 0.0461],\n",
       "           [0.0116, 0.0402, 0.5719, 0.0031]],\n",
       "\n",
       "          [[0.0154, 0.2209, 0.1501, 0.1474],\n",
       "           [0.2002, 0.0531, 0.0214, 0.7154],\n",
       "           [0.1658, 0.9345, 0.1328, 0.5711],\n",
       "           [0.0722, 0.0432, 0.1777, 0.0941]]],\n",
       "\n",
       "\n",
       "         [[[0.1076, 0.0003, 0.5558, 0.0130],\n",
       "           [0.0001, 0.4150, 0.2270, 0.3135],\n",
       "           [0.1584, 0.1728, 0.2871, 0.0728],\n",
       "           [0.0511, 0.0678, 0.1449, 0.0081]],\n",
       "\n",
       "          [[0.1187, 0.0087, 0.6043, 0.0079],\n",
       "           [0.0972, 0.8651, 0.1980, 0.2210],\n",
       "           [0.0961, 0.1467, 0.2334, 0.8110],\n",
       "           [0.1913, 0.0150, 0.1086, 0.0200]]],\n",
       "\n",
       "\n",
       "         [[[0.2854, 0.5859, 0.2620, 0.3562],\n",
       "           [0.4604, 0.1728, 0.0634, 0.3229],\n",
       "           [0.5514, 0.2828, 0.1512, 0.1551],\n",
       "           [0.0088, 0.1338, 0.3289, 0.2181]],\n",
       "\n",
       "          [[0.0764, 0.3934, 0.4782, 0.0803],\n",
       "           [0.0553, 0.2006, 0.0029, 0.5332],\n",
       "           [0.2462, 0.2248, 0.2314, 0.4961],\n",
       "           [0.1583, 0.3318, 0.3908, 0.5970]]]]])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 4, 4])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.view(y.size(0),-1,y.size(3),y.size(4)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 4: Index tensor must have same dimensions as input tensor at /opt/conda/conda-bld/pytorch_1535493744281/work/aten/src/TH/generic/THTensorMath.cpp:601",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-f39e43a05592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 4: Index tensor must have same dimensions as input tensor at /opt/conda/conda-bld/pytorch_1535493744281/work/aten/src/TH/generic/THTensorMath.cpp:601"
     ]
    }
   ],
   "source": [
    "output.gather(1,id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2,6,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.view(x.size(0),-1,2,x.size(2),x.size(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9014, 0.7832],\n",
       "         [0.0354, 0.2964]],\n",
       "\n",
       "        [[0.4467, 0.0210],\n",
       "         [0.1566, 0.4616]],\n",
       "\n",
       "        [[0.3397, 0.6119],\n",
       "         [0.8065, 0.9524]]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0:3,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4467, 0.0210],\n",
       "         [0.1566, 0.4616]],\n",
       "\n",
       "        [[0.8846, 0.4512],\n",
       "         [0.9043, 0.6589]],\n",
       "\n",
       "        [[0.6576, 0.8447],\n",
       "         [0.3778, 0.5791]]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0,:,1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xh/miniconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([0,0])\n",
    "a/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OffsetLoss(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(OffsetLoss, self).__init__()\n",
    "  \n",
    "  def forward(self, output, mask, ind, target, rel_id, heatmap_mask):\n",
    "    pred = _offset_format(output, rel_id)\n",
    "    heatmap_mask = heatmap_mask.unsqueeze(2).expand_as(pred).float()\n",
    "    # loss = F.l1_loss(pred * heatmap_mask, target * heatmap_mask, reduction='elementwise_mean')\n",
    "    loss = F.l1_loss(pred * heatmap_mask, target * heatmap_mask, size_average=False)\n",
    "    mask = mask.float()\n",
    "    loss = loss / (mask.sum() + 1e-4)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = OffsetLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch0.4",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
