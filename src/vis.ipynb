{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tensorboardX\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import _init_paths\n",
    "import torch\n",
    "import tensorwatch as tw\n",
    "from models.model import create_model, load_model, save_model\n",
    "from models.data_parallel import DataParallel\n",
    "from logger import Logger\n",
    "from datasets.dataset_factory import get_dataset\n",
    "from trains.train_factory import train_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "class opts(object):\n",
    "    def __init__(self):\n",
    "        self.parser = argparse.ArgumentParser()\n",
    "        # basic experiment setting\n",
    "        self.parser.add_argument('--task', default='hoidet',\n",
    "                                 help='ctdet | ddd | multi_pose | exdet')\n",
    "        self.parser.add_argument('--dataset', default='hico',\n",
    "                                 help='hico | vcoco | hoia')\n",
    "        self.parser.add_argument('--exp_id', default='default')\n",
    "        self.parser.add_argument('--test', action='store_true')\n",
    "        self.parser.add_argument('--debug', type=int, default=0,\n",
    "                                 help='level of visualization.'\n",
    "                                      '1: only show the final detection results'\n",
    "                                      '2: show the network output features'\n",
    "                                      '3: use matplot to display'  # useful when lunching training with ipython notebook\n",
    "                                      '4: save all visualizations to disk')\n",
    "        self.parser.add_argument('--demo', default='',\n",
    "                                 help='path to image/ image folders/ video. '\n",
    "                                      'or \"webcam\"')\n",
    "        self.parser.add_argument('--load_model', default='',\n",
    "                                 help='path to pretrained model')\n",
    "        self.parser.add_argument('--resume', action='store_true',\n",
    "                                 help='resume an experiment. '\n",
    "                                      'Reloaded the optimizer parameter and '\n",
    "                                      'set load_model to model_last.pth '\n",
    "                                      'in the exp dir if load_model is empty.')\n",
    "\n",
    "        # system\n",
    "        self.parser.add_argument('--gpus', default='0',\n",
    "                                 help='-1 for CPU, use comma for multiple gpus')\n",
    "        self.parser.add_argument('--num_workers', type=int, default=4,\n",
    "                                 help='dataloader threads. 0 for single-thread.')\n",
    "        self.parser.add_argument('--not_cuda_benchmark', action='store_true',\n",
    "                                 help='disable when the input size is not fixed.')\n",
    "        self.parser.add_argument('--seed', type=int, default=317,\n",
    "                                 help='random seed')  # from CornerNet\n",
    "\n",
    "        # log\n",
    "        self.parser.add_argument('--print_iter', type=int, default=0,\n",
    "                                 help='disable progress bar and print to screen.')\n",
    "        self.parser.add_argument('--hide_data_time', action='store_true',\n",
    "                                 help='not display time during training.')\n",
    "        self.parser.add_argument('--save_all', action='store_true',\n",
    "                                 help='save model to disk every 5 epochs.')\n",
    "        self.parser.add_argument('--metric', default='loss',\n",
    "                                 help='main metric to save best model')\n",
    "        self.parser.add_argument('--vis_thresh', type=float, default=0.3,\n",
    "                                 help='visualization threshold.')\n",
    "        self.parser.add_argument('--debugger_theme', default='white',\n",
    "                                 choices=['white', 'black'])\n",
    "\n",
    "        # model\n",
    "        self.parser.add_argument('--arch', default='dla_34',\n",
    "                                 help='model architecture. Currently tested'\n",
    "                                      'res_18 | resdcn_18 | dla_34 | hourglass')\n",
    "        self.parser.add_argument('--head_conv', type=int, default=-1,\n",
    "                                 help='conv layer channels for output head'\n",
    "                                      '0 for no conv layer'\n",
    "                                      '-1 for default setting: '\n",
    "                                      '64 for resnets and 256 for dla.')\n",
    "        self.parser.add_argument('--down_ratio', type=int, default=4,\n",
    "                                 help='output stride. Currently only supports 4.')\n",
    "\n",
    "        # input\n",
    "        self.parser.add_argument('--input_res', type=int, default=-1,\n",
    "                                 help='input height and width. -1 for default from '\n",
    "                                      'dataset. Will be overriden by input_h | input_w')\n",
    "        self.parser.add_argument('--input_h', type=int, default=-1,\n",
    "                                 help='input height. -1 for default from dataset.')\n",
    "        self.parser.add_argument('--input_w', type=int, default=-1,\n",
    "                                 help='input width. -1 for default from dataset.')\n",
    "\n",
    "        # train\n",
    "        self.parser.add_argument('--lr', type=float, default=1.25e-4,\n",
    "                                 help='learning rate for batch size 32.')\n",
    "        self.parser.add_argument('--lr_step', type=str, default='90,120',\n",
    "                                 help='drop learning rate by 10.')\n",
    "        self.parser.add_argument('--num_epochs', type=int, default=140,\n",
    "                                 help='total training epochs.')\n",
    "        self.parser.add_argument('--batch_size', type=int, default=32,\n",
    "                                 help='batch size')\n",
    "        self.parser.add_argument('--master_batch_size', type=int, default=-1,\n",
    "                                 help='batch size on the master gpu.')\n",
    "        self.parser.add_argument('--num_iters', type=int, default=-1,\n",
    "                                 help='default: #samples / batch_size.')\n",
    "        self.parser.add_argument('--val_intervals', type=int, default=100000,\n",
    "                                 help='number of epochs to run validation.')\n",
    "        self.parser.add_argument('--trainval', action='store_true',\n",
    "                                 help='include validation in training and '\n",
    "                                      'test on test set')\n",
    "\n",
    "        # test\n",
    "        self.parser.add_argument('--flip_test', action='store_true',\n",
    "                                 help='flip data augmentation.')\n",
    "        self.parser.add_argument('--test_scales', type=str, default='1',\n",
    "                                 help='multi scale test augmentation.')\n",
    "        self.parser.add_argument('--nms', action='store_true',\n",
    "                                 help='run nms in testing.')\n",
    "        self.parser.add_argument('--K', type=int, default=100,\n",
    "                                 help='max number of output objects.')\n",
    "        self.parser.add_argument('--not_prefetch_test', action='store_true',\n",
    "                                 help='not use parallal data pre-processing.')\n",
    "        self.parser.add_argument('--fix_res', action='store_true',\n",
    "                                 help='fix testing resolution or keep '\n",
    "                                      'the original resolution')\n",
    "        self.parser.add_argument('--keep_res', action='store_true',\n",
    "                                 help='keep the original resolution'\n",
    "                                      ' during validation.')\n",
    "        self.parser.add_argument('--save_predictions', action='store_true',\n",
    "                                 help='saving predictions when testing')\n",
    "        self.parser.add_argument('--test_with_eval', action='store_true',\n",
    "                                 help='do evaluation when testing')\n",
    "        self.parser.add_argument('--test_video', action='store_true',\n",
    "                                 help='inference with a video')\n",
    "        self.parser.add_argument('--test_dir', type=str,default='',\n",
    "                                 help='the video path')\n",
    "        self.parser.add_argument('--save_video', type=str,default='',\n",
    "                                 help='the video save path')\n",
    "\n",
    "        # dataset\n",
    "        self.parser.add_argument('--not_rand_crop', action='store_true',\n",
    "                                 help='not use the random crop data augmentation'\n",
    "                                      'from CornerNet.')\n",
    "        self.parser.add_argument('--shift', type=float, default=0.1,\n",
    "                                 help='when not using random crop'\n",
    "                                      'apply shift augmentation.')\n",
    "        self.parser.add_argument('--scale', type=float, default=0.4,\n",
    "                                 help='when not using random crop'\n",
    "                                      'apply scale augmentation.')\n",
    "        self.parser.add_argument('--rotate', type=float, default=0,\n",
    "                                 help='when not using random crop'\n",
    "                                      'apply rotation augmentation.')\n",
    "        self.parser.add_argument('--flip', type=float, default=0.5,\n",
    "                                 help='probability of applying flip augmentation.')\n",
    "        self.parser.add_argument('--no_color_aug', action='store_true',\n",
    "                                 help='not use the color augmenation '\n",
    "                                      'from CornerNet')\n",
    "\n",
    "\n",
    "        # loss\n",
    "        self.parser.add_argument('--mse_loss', action='store_true',\n",
    "                                 help='use mse loss or focal loss to train '\n",
    "                                      'keypoint heatmaps.')\n",
    "        # ctdet\n",
    "        self.parser.add_argument('--reg_loss', default='l1',\n",
    "                                 help='regression loss: sl1 | l1 | l2')\n",
    "        self.parser.add_argument('--hm_weight', type=float, default=1,\n",
    "                                 help='loss weight for keypoint heatmaps.')\n",
    "        self.parser.add_argument('--off_weight', type=float, default=1,\n",
    "                                 help='loss weight for keypoint local offsets.')\n",
    "        self.parser.add_argument('--wh_weight', type=float, default=0.1,\n",
    "                                 help='loss weight for bounding box size.')\n",
    "\n",
    "        # task\n",
    "        # ctdet\n",
    "        self.parser.add_argument('--norm_wh', action='store_true',\n",
    "                                 help='L1(\\hat(y) / y, 1) or L1(\\hat(y), y)')\n",
    "        self.parser.add_argument('--dense_wh', action='store_true',\n",
    "                                 help='apply weighted regression near center or '\n",
    "                                      'just apply regression on center point.')\n",
    "        self.parser.add_argument('--cat_spec_wh', action='store_true',\n",
    "                                 help='category specific bounding box size.')\n",
    "        self.parser.add_argument('--not_reg_offset', action='store_true',\n",
    "                                 help='not regress local offset.')\n",
    "\n",
    "        # ground truth validation\n",
    "        self.parser.add_argument('--image_dir', type=str, default='images/trainval',\n",
    "                                 help='training dataset path.')\n",
    "        self.parser.add_argument('--root_path', type=str, default='../Dataset',\n",
    "                                 help='training dataset path.')\n",
    "        self.parser.add_argument('--use_cos', type=int, default=0\n",
    "                                 , help='whether using cosine lr step policy')\n",
    "        self.parser.add_argument('--use_verb_sub', type=int, default=0\n",
    "                                 , help='whether using verb categories for subject')\n",
    "\n",
    "    def parse(self, args=''):\n",
    "        opt = self.parser.parse_known_args()[0]\n",
    "        print(opt.task)\n",
    "        opt.gpus_str = opt.gpus\n",
    "        opt.gpus = [int(gpu) for gpu in opt.gpus.split(',')]\n",
    "        opt.gpus = [i for i in range(len(opt.gpus))] if opt.gpus[0] >= 0 else [-1]\n",
    "        opt.lr_step = [int(i) for i in opt.lr_step.split(',')]\n",
    "        opt.test_scales = [float(i) for i in opt.test_scales.split(',')]\n",
    "\n",
    "        opt.fix_res = not opt.keep_res\n",
    "        print('Fix size testing.' if opt.fix_res else 'Keep resolution testing.')\n",
    "        opt.reg_offset = not opt.not_reg_offset\n",
    "\n",
    "        if opt.head_conv == -1:  # init default head_conv\n",
    "            opt.head_conv = 256 if 'dla' in opt.arch else 64\n",
    "        opt.pad = 127 if 'hourglass' in opt.arch else 31\n",
    "        opt.num_stacks = 2 if opt.arch == 'hourglass' else 1\n",
    "\n",
    "        if opt.trainval:\n",
    "            opt.val_intervals = 100000000\n",
    "\n",
    "        if opt.debug > 0:\n",
    "            opt.num_workers = 0\n",
    "            opt.batch_size = 1\n",
    "            opt.gpus = [opt.gpus[0]]\n",
    "            opt.master_batch_size = -1\n",
    "\n",
    "        if opt.master_batch_size == -1:\n",
    "            opt.master_batch_size = opt.batch_size // len(opt.gpus)\n",
    "        rest_batch_size = (opt.batch_size - opt.master_batch_size)\n",
    "        opt.chunk_sizes = [opt.master_batch_size]\n",
    "        for i in range(len(opt.gpus) - 1):\n",
    "            slave_chunk_size = rest_batch_size // (len(opt.gpus) - 1)\n",
    "            if i < rest_batch_size % (len(opt.gpus) - 1):\n",
    "                slave_chunk_size += 1\n",
    "            opt.chunk_sizes.append(slave_chunk_size)\n",
    "        print('training chunk_sizes:', opt.chunk_sizes)\n",
    "\n",
    "\n",
    "        if opt.resume and opt.load_model == '':\n",
    "            model_path = opt.save_dir[:-4] if opt.save_dir.endswith('TEST') \\\n",
    "                else opt.save_dir\n",
    "            opt.load_model = os.path.join(model_path, 'model_last.pth')\n",
    "        return opt\n",
    "\n",
    "    def update_dataset_info_and_set_heads(self, opt, dataset):\n",
    "        input_h, input_w = dataset.default_resolution\n",
    "        opt.mean, opt.std = dataset.mean, dataset.std\n",
    "        opt.num_classes = dataset.num_classes\n",
    "        opt.num_classes_verb = dataset.num_classes_verb\n",
    "        # input_h(w): opt.input_h overrides opt.input_res overrides dataset default\n",
    "        input_h = opt.input_res if opt.input_res > 0 else input_h\n",
    "        input_w = opt.input_res if opt.input_res > 0 else input_w\n",
    "        opt.input_h = opt.input_h if opt.input_h > 0 else input_h\n",
    "        opt.input_w = opt.input_w if opt.input_w > 0 else input_w\n",
    "        opt.output_h = opt.input_h // opt.down_ratio\n",
    "        opt.output_w = opt.input_w // opt.down_ratio\n",
    "        opt.input_res = max(opt.input_h, opt.input_w)\n",
    "        opt.output_res = max(opt.output_h, opt.output_w)\n",
    "\n",
    "\n",
    "        if opt.task == 'hoidet':\n",
    "            assert opt.dataset in ['hico', 'vcoco', 'hoia']\n",
    "            opt.heads = {'hm': opt.num_classes,\n",
    "                         'wh': 2 if not opt.cat_spec_wh else 2 * opt.num_classes,\n",
    "                         'hm_rel': opt.num_classes_verb,\n",
    "                         'sub_offset': 2 * opt.num_classes_verb,\n",
    "                         'obj_offset': 2 * opt.num_classes_verb}\n",
    "            if opt.reg_offset:\n",
    "                opt.heads.update({'reg': 2})\n",
    "        else:\n",
    "            assert 0, 'task not defined!'\n",
    "        print('heads', opt.heads)\n",
    "        return opt\n",
    "\n",
    "    def init(self, args=''):\n",
    "        default_dataset_info = {\n",
    "            'hoidet': {'default_resolution': [512, 512], 'num_classes': 80,\n",
    "                  'mean': [0.408, 0.447, 0.470], 'std': [0.289, 0.274, 0.278],\n",
    "                  'dataset': 'hico', 'num_classes_verb': 117}\n",
    "        }\n",
    "\n",
    "        class Struct:\n",
    "            def __init__(self, entries):\n",
    "                for k, v in entries.items():\n",
    "                    self.__setattr__(k, v)\n",
    "\n",
    "        opt = self.parse(args)\n",
    "        dataset = Struct(default_dataset_info[opt.task])\n",
    "        opt.dataset = dataset.dataset\n",
    "        opt = self.update_dataset_info_and_set_heads(opt, dataset)\n",
    "        return opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database is locked')).History will not be written to the database.hoidet\n",
      "\n",
      "Fix size testing.\n",
      "training chunk_sizes: [32]\n"
     ]
    }
   ],
   "source": [
    "opt = opts().parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heads {'hm': 80, 'wh': 2, 'hm_rel': 117, 'sub_offset': 234, 'obj_offset': 234, 'reg': 2}\n",
      "Namespace(K=100, arch='dla_34', batch_size=32, cat_spec_wh=False, chunk_sizes=[32], dataset='hico', debug=0, debugger_theme='white', demo='', dense_wh=False, down_ratio=4, exp_id='default', fix_res=True, flip=0.5, flip_test=False, gpus=[0], gpus_str='0', head_conv=256, heads={'hm': 80, 'wh': 2, 'hm_rel': 117, 'sub_offset': 234, 'obj_offset': 234, 'reg': 2}, hide_data_time=False, hm_weight=1, image_dir='images/trainval', input_h=512, input_res=512, input_w=512, keep_res=False, load_model='', lr=0.000125, lr_step=[90, 120], master_batch_size=32, mean=array([[[0.40789655, 0.44719303, 0.47026116]]], dtype=float32), metric='loss', mse_loss=False, nms=False, no_color_aug=False, norm_wh=False, not_cuda_benchmark=False, not_prefetch_test=False, not_rand_crop=False, not_reg_offset=False, num_classes=80, num_classes_verb=117, num_epochs=140, num_iters=-1, num_stacks=1, num_workers=4, off_weight=1, output_h=128, output_res=128, output_w=128, pad=31, print_iter=0, reg_loss='l1', reg_offset=True, resume=False, root_path='../Dataset', rotate=0, save_all=False, save_predictions=False, save_video='', scale=0.4, seed=317, shift=0.1, std=array([[[0.2886383 , 0.27408165, 0.27809834]]], dtype=float32), task='hoidet', test=False, test_dir='', test_scales=[1.0], test_video=False, test_with_eval=False, trainval=False, use_cos=0, use_verb_sub=0, val_intervals=100000, vis_thresh=0.3, wh_weight=0.1)\n"
     ]
    }
   ],
   "source": [
    "Dataset = get_dataset(opt.dataset)\n",
    "opt = opts().update_dataset_info_and_set_heads(opt, Dataset)\n",
    "print(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(opt.arch, opt.heads, opt.head_conv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLASeg(\n",
      "  (base): DLA(\n",
      "    (base_layer): Sequential(\n",
      "      (0): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (level0): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (level1): Sequential(\n",
      "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (level2): Tree(\n",
      "      (tree1): BasicBlock(\n",
      "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (tree2): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (root): Root(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (project): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (level3): Tree(\n",
      "      (tree1): Tree(\n",
      "        (tree1): BasicBlock(\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (tree2): BasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (root): Root(\n",
      "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "        (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (project): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (tree2): Tree(\n",
      "        (tree1): BasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (tree2): BasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (root): Root(\n",
      "          (conv): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (project): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (level4): Tree(\n",
      "      (tree1): Tree(\n",
      "        (tree1): BasicBlock(\n",
      "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (tree2): BasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (root): Root(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "        (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (project): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (tree2): Tree(\n",
      "        (tree1): BasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (tree2): BasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (root): Root(\n",
      "          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (project): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (level5): Tree(\n",
      "      (tree1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (tree2): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (root): Root(\n",
      "        (conv): Conv2d(1280, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (project): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (fc): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (dla_up): DLAUp(\n",
      "    (ida_0): IDAUp(\n",
      "      (proj_1): DeformConv(\n",
      "        (actf): Sequential(\n",
      "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (conv): DCN(\n",
      "          (conv_offset_mask): Conv2d(512, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (up_1): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
      "      (node_1): DeformConv(\n",
      "        (actf): Sequential(\n",
      "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (conv): DCN(\n",
      "          (conv_offset_mask): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ida_1): IDAUp(\n",
      "      (proj_1): DeformConv(\n",
      "        (actf): Sequential(\n",
      "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (conv): DCN(\n",
      "          (conv_offset_mask): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (up_1): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "      (node_1): DeformConv(\n",
      "        (actf): Sequential(\n",
      "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (conv): DCN(\n",
      "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (proj_2): DeformConv(\n",
      "        (actf): Sequential(\n",
      "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (conv): DCN(\n",
      "          (conv_offset_mask): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (up_2): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "      (node_2): DeformConv(\n",
      "        (actf): Sequential(\n",
      "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (conv): DCN(\n",
      "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ida_2): IDAUp(\n",
      "      (proj_1): DeformConv(\n",
      "        (actf): Sequential(\n",
      "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (conv): DCN(\n",
      "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (up_1): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "      (node_1): DeformConv(\n",
      "        (actf): Sequential(\n",
      "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (conv): DCN(\n",
      "          (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (proj_2): DeformConv(\n",
      "        (actf): Sequential(\n",
      "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (conv): DCN(\n",
      "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (up_2): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "      (node_2): DeformConv(\n",
      "        (actf): Sequential(\n",
      "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (conv): DCN(\n",
      "          (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (proj_3): DeformConv(\n",
      "        (actf): Sequential(\n",
      "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (conv): DCN(\n",
      "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (up_3): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "      (node_3): DeformConv(\n",
      "        (actf): Sequential(\n",
      "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (conv): DCN(\n",
      "          (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ida_up): IDAUp(\n",
      "    (proj_1): DeformConv(\n",
      "      (actf): Sequential(\n",
      "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU(inplace)\n",
      "      )\n",
      "      (conv): DCN(\n",
      "        (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (up_1): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "    (node_1): DeformConv(\n",
      "      (actf): Sequential(\n",
      "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU(inplace)\n",
      "      )\n",
      "      (conv): DCN(\n",
      "        (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (proj_2): DeformConv(\n",
      "      (actf): Sequential(\n",
      "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU(inplace)\n",
      "      )\n",
      "      (conv): DCN(\n",
      "        (conv_offset_mask): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (up_2): ConvTranspose2d(64, 64, kernel_size=(8, 8), stride=(4, 4), padding=(2, 2), groups=64, bias=False)\n",
      "    (node_2): DeformConv(\n",
      "      (actf): Sequential(\n",
      "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU(inplace)\n",
      "      )\n",
      "      (conv): DCN(\n",
      "        (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (hm): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (wh): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (hm_rel): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(256, 117, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (sub_offset): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(256, 234, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (obj_offset): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(256, 234, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (reg): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.rand(1,3,512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DLASeg(\n",
       "  (base): DLA(\n",
       "    (base_layer): Sequential(\n",
       "      (0): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace)\n",
       "    )\n",
       "    (level0): Sequential(\n",
       "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace)\n",
       "    )\n",
       "    (level1): Sequential(\n",
       "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace)\n",
       "    )\n",
       "    (level2): Tree(\n",
       "      (tree1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (tree2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (root): Root(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (level3): Tree(\n",
       "      (tree1): Tree(\n",
       "        (tree1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (tree2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (root): Root(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (project): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (tree2): Tree(\n",
       "        (tree1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (tree2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (root): Root(\n",
       "          (conv): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (level4): Tree(\n",
       "      (tree1): Tree(\n",
       "        (tree1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (tree2): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (root): Root(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (project): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (tree2): Tree(\n",
       "        (tree1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (tree2): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (root): Root(\n",
       "          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (level5): Tree(\n",
       "      (tree1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (tree2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (root): Root(\n",
       "        (conv): Conv2d(1280, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (fc): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (dla_up): DLAUp(\n",
       "    (ida_0): IDAUp(\n",
       "      (proj_1): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): DCN(\n",
       "          (conv_offset_mask): Conv2d(512, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (up_1): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "      (node_1): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): DCN(\n",
       "          (conv_offset_mask): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ida_1): IDAUp(\n",
       "      (proj_1): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): DCN(\n",
       "          (conv_offset_mask): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (up_1): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "      (node_1): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): DCN(\n",
       "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (proj_2): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): DCN(\n",
       "          (conv_offset_mask): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (up_2): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "      (node_2): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): DCN(\n",
       "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ida_2): IDAUp(\n",
       "      (proj_1): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): DCN(\n",
       "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (up_1): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "      (node_1): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): DCN(\n",
       "          (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (proj_2): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): DCN(\n",
       "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (up_2): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "      (node_2): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): DCN(\n",
       "          (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (proj_3): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): DCN(\n",
       "          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (up_3): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "      (node_3): DeformConv(\n",
       "        (actf): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace)\n",
       "        )\n",
       "        (conv): DCN(\n",
       "          (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ida_up): IDAUp(\n",
       "    (proj_1): DeformConv(\n",
       "      (actf): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace)\n",
       "      )\n",
       "      (conv): DCN(\n",
       "        (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (up_1): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "    (node_1): DeformConv(\n",
       "      (actf): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace)\n",
       "      )\n",
       "      (conv): DCN(\n",
       "        (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (proj_2): DeformConv(\n",
       "      (actf): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace)\n",
       "      )\n",
       "      (conv): DCN(\n",
       "        (conv_offset_mask): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (up_2): ConvTranspose2d(64, 64, kernel_size=(8, 8), stride=(4, 4), padding=(2, 2), groups=64, bias=False)\n",
       "    (node_2): DeformConv(\n",
       "      (actf): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace)\n",
       "      )\n",
       "      (conv): DCN(\n",
       "        (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (hm): Sequential(\n",
       "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (wh): Sequential(\n",
       "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (hm_rel): Sequential(\n",
       "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(256, 117, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (sub_offset): Sequential(\n",
       "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(256, 234, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (obj_offset): Sequential(\n",
       "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(256, 234, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (reg): Sequential(\n",
       "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(inp.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hm torch.Size([1, 80, 128, 128])\n",
      "wh torch.Size([1, 2, 128, 128])\n",
      "hm_rel torch.Size([1, 117, 128, 128])\n",
      "sub_offset torch.Size([1, 234, 128, 128])\n",
      "obj_offset torch.Size([1, 234, 128, 128])\n",
      "reg torch.Size([1, 2, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "for key in out[0]:\n",
    "    print(key,out[0][key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoi_annotation = json.load(open('../Dataset/hico_det/annotations/trainval_hico.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(hoi_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'HICO_train2015_00000010.jpg',\n",
       " 'img_id': 10,\n",
       " 'annotations': [{'bbox': [266, 69, 369, 273], 'category_id': 1},\n",
       "  {'bbox': [111, 69, 442, 410], 'category_id': 19},\n",
       "  {'bbox': [282, 65, 353, 288], 'category_id': 1},\n",
       "  {'bbox': [97, 68, 448, 416], 'category_id': 19}],\n",
       " 'hoi_annotation': [{'subject_id': 0,\n",
       "   'object_id': 1,\n",
       "   'category_id': 37,\n",
       "   'hoi_category_id': 132},\n",
       "  {'subject_id': 0, 'object_id': 1, 'category_id': 77, 'hoi_category_id': 140},\n",
       "  {'subject_id': 2,\n",
       "   'object_id': 3,\n",
       "   'category_id': 99,\n",
       "   'hoi_category_id': 142}]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hoi_annotation[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37633"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hoi_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.new_zeros((8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[6.4284e-01, 4.5300e-01, 1.6063e-01,  ..., 8.3155e-01,\n",
       "           6.7112e-01, 7.4838e-02],\n",
       "          [2.5540e-01, 5.5879e-01, 2.9102e-01,  ..., 1.9157e-02,\n",
       "           7.3649e-01, 9.4765e-01],\n",
       "          [9.7452e-01, 6.1641e-01, 2.4284e-01,  ..., 1.6031e-01,\n",
       "           9.7933e-01, 1.6624e-01],\n",
       "          ...,\n",
       "          [3.0959e-02, 8.5629e-01, 4.1204e-01,  ..., 1.4710e-01,\n",
       "           5.7472e-01, 9.9365e-01],\n",
       "          [6.3456e-01, 2.4013e-01, 8.8683e-01,  ..., 9.6062e-01,\n",
       "           2.2913e-01, 9.9980e-01],\n",
       "          [1.8317e-01, 8.2605e-01, 8.7873e-01,  ..., 9.0550e-01,\n",
       "           9.7295e-01, 8.4975e-01]],\n",
       "\n",
       "         [[1.5791e-01, 7.9024e-01, 1.6684e-01,  ..., 3.7241e-01,\n",
       "           6.7908e-01, 9.9644e-01],\n",
       "          [6.6486e-01, 2.0115e-02, 9.6444e-01,  ..., 1.8604e-01,\n",
       "           6.0808e-01, 9.3466e-01],\n",
       "          [3.7497e-01, 7.2220e-01, 8.1125e-01,  ..., 6.7297e-01,\n",
       "           5.8954e-01, 7.1415e-02],\n",
       "          ...,\n",
       "          [2.6642e-01, 3.2239e-01, 3.9868e-02,  ..., 4.4832e-01,\n",
       "           5.5324e-01, 9.8873e-01],\n",
       "          [2.8196e-01, 9.8374e-02, 4.4000e-01,  ..., 2.5574e-01,\n",
       "           2.3767e-01, 6.2364e-01],\n",
       "          [8.5156e-01, 1.3360e-01, 4.6940e-01,  ..., 5.0062e-02,\n",
       "           3.3854e-02, 6.3961e-01]],\n",
       "\n",
       "         [[8.4815e-01, 4.1732e-02, 6.8308e-01,  ..., 2.1128e-01,\n",
       "           3.6663e-01, 1.2396e-01],\n",
       "          [7.4596e-02, 2.4783e-02, 3.6142e-01,  ..., 8.7077e-01,\n",
       "           6.5555e-01, 4.9992e-01],\n",
       "          [1.6596e-01, 1.0583e-01, 2.9733e-01,  ..., 1.9274e-02,\n",
       "           2.6243e-01, 7.8596e-01],\n",
       "          ...,\n",
       "          [2.0280e-01, 7.1224e-01, 1.9318e-01,  ..., 3.7877e-01,\n",
       "           9.3302e-01, 5.9391e-01],\n",
       "          [5.9553e-01, 1.9753e-01, 9.7409e-01,  ..., 5.0560e-01,\n",
       "           3.8115e-01, 3.4428e-01],\n",
       "          [8.8715e-01, 9.9536e-01, 8.1507e-01,  ..., 7.8270e-01,\n",
       "           4.5301e-01, 1.2231e-01]]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "_valid_ids_verb = list(range(118))\n",
    "_valid_ids_verb.remove(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_ids_verb = {v: i for i, v in enumerate(_valid_ids_verb)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0,\n",
       " 2: 1,\n",
       " 3: 2,\n",
       " 4: 3,\n",
       " 5: 4,\n",
       " 6: 5,\n",
       " 7: 6,\n",
       " 8: 7,\n",
       " 9: 8,\n",
       " 10: 9,\n",
       " 11: 10,\n",
       " 12: 11,\n",
       " 13: 12,\n",
       " 14: 13,\n",
       " 15: 14,\n",
       " 16: 15,\n",
       " 17: 16,\n",
       " 18: 17,\n",
       " 19: 18,\n",
       " 20: 19,\n",
       " 21: 20,\n",
       " 22: 21,\n",
       " 23: 22,\n",
       " 24: 23,\n",
       " 25: 24,\n",
       " 26: 25,\n",
       " 27: 26,\n",
       " 28: 27,\n",
       " 29: 28,\n",
       " 30: 29,\n",
       " 31: 30,\n",
       " 32: 31,\n",
       " 33: 32,\n",
       " 34: 33,\n",
       " 35: 34,\n",
       " 36: 35,\n",
       " 37: 36,\n",
       " 38: 37,\n",
       " 39: 38,\n",
       " 40: 39,\n",
       " 41: 40,\n",
       " 42: 41,\n",
       " 43: 42,\n",
       " 44: 43,\n",
       " 45: 44,\n",
       " 46: 45,\n",
       " 47: 46,\n",
       " 48: 47,\n",
       " 49: 48,\n",
       " 50: 49,\n",
       " 51: 50,\n",
       " 52: 51,\n",
       " 53: 52,\n",
       " 54: 53,\n",
       " 55: 54,\n",
       " 56: 55,\n",
       " 57: 56,\n",
       " 58: 57,\n",
       " 59: 58,\n",
       " 60: 59,\n",
       " 61: 60,\n",
       " 62: 61,\n",
       " 63: 62,\n",
       " 64: 63,\n",
       " 65: 64,\n",
       " 66: 65,\n",
       " 67: 66,\n",
       " 68: 67,\n",
       " 69: 68,\n",
       " 70: 69,\n",
       " 71: 70,\n",
       " 72: 71,\n",
       " 73: 72,\n",
       " 74: 73,\n",
       " 75: 74,\n",
       " 76: 75,\n",
       " 77: 76,\n",
       " 78: 77,\n",
       " 79: 78,\n",
       " 80: 79,\n",
       " 81: 80,\n",
       " 82: 81,\n",
       " 83: 82,\n",
       " 84: 83,\n",
       " 85: 84,\n",
       " 86: 85,\n",
       " 87: 86,\n",
       " 88: 87,\n",
       " 89: 88,\n",
       " 90: 89,\n",
       " 91: 90,\n",
       " 92: 91,\n",
       " 93: 92,\n",
       " 94: 93,\n",
       " 95: 94,\n",
       " 96: 95,\n",
       " 97: 96,\n",
       " 98: 97,\n",
       " 99: 98,\n",
       " 100: 99,\n",
       " 101: 100,\n",
       " 102: 101,\n",
       " 103: 102,\n",
       " 104: 103,\n",
       " 105: 104,\n",
       " 106: 105,\n",
       " 107: 106,\n",
       " 108: 107,\n",
       " 109: 108,\n",
       " 110: 109,\n",
       " 111: 110,\n",
       " 112: 111,\n",
       " 113: 112,\n",
       " 114: 113,\n",
       " 115: 114,\n",
       " 116: 115,\n",
       " 117: 116}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_ids_verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_gaussian_mask(heatmap, center, sigma):\n",
    "  tmp_size = sigma * 3\n",
    "  mu_x = int(center[0] + 0.5)\n",
    "  mu_y = int(center[1] + 0.5)\n",
    "  w, h = heatmap.shape[0], heatmap.shape[1]\n",
    "  ul = [int(mu_x - tmp_size), int(mu_y - tmp_size)]\n",
    "  br = [int(mu_x + tmp_size + 1), int(mu_y + tmp_size + 1)]\n",
    "  if ul[0] >= h or ul[1] >= w or br[0] < 0 or br[1] < 0:\n",
    "    return heatmap\n",
    "  size = 2 * tmp_size + 1\n",
    "  x = np.arange(0, size, 1, np.float32)\n",
    "  y = x[:, np.newaxis]\n",
    "  x0 = y0 = size // 2\n",
    "  g = np.exp(- ((x - x0) ** 2 + (y - y0) ** 2) / (2 * sigma ** 2))\n",
    "  g_x = max(0, -ul[0]), min(br[0], h) - ul[0]\n",
    "  g_y = max(0, -ul[1]), min(br[1], w) - ul[1]\n",
    "  img_x = max(0, ul[0]), min(br[0], h)\n",
    "  img_y = max(0, ul[1]), min(br[1], w)\n",
    "  heatmap[img_y[0]:img_y[1], img_x[0]:img_x[1]] = np.maximum(\n",
    "    heatmap[img_y[0]:img_y[1], img_x[0]:img_x[1]],\n",
    "    g[g_y[0]:g_y[1], g_x[0]:g_x[1]])\n",
    "  \n",
    "  return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = np.zeros((8,8),dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = draw_gaussian_mask(heatmap,(4,4),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[x>0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = np.zeros((8, 2, 8, 8), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2, 8, 8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "off = offset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(off.shape[1]):\n",
    "    for j in range(off.shape[2]):\n",
    "        off[:,i,j] = i-0,j-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2.], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off[:,1,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_offset(offset_heatmap, point):\n",
    "  x,y = point\n",
    "  for i in range(offset_heatmap.shape[1]):\n",
    "      for j in range(offset_heatmap.shape[2]):\n",
    "          offset_heatmap[:,i,j] = i-x,j-y\n",
    "  return offset_heatmap  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.],\n",
       "        [ 3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.],\n",
       "        [ 4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.],\n",
       "        [ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.],\n",
       "        [ 6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.],\n",
       "        [ 7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.]],\n",
       "\n",
       "       [[-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.]]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_offset(off,[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.],\n",
       "        [ 3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.],\n",
       "        [ 4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.],\n",
       "        [ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.],\n",
       "        [ 6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.],\n",
       "        [ 7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.]],\n",
       "\n",
       "       [[-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [-1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.]]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch0.4",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
